{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, when\n",
    "\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from sedona.core.formatMapper.shapefileParser import ShapefileReader\n",
    "from sedona.utils.adapter import Adapter\n",
    "from sedona.core.enums import GridType\n",
    "from sedona.core.enums import IndexType\n",
    "from sedona.core.spatialOperator import JoinQueryRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "        master(\"local[*]\").\\\n",
    "        appName(\"SedonaSQL-Example\").\\\n",
    "        config(\"spark.serializer\", KryoSerializer.getName).\\\n",
    "        config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) .\\\n",
    "        config('spark.jars.packages',\n",
    "               'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.1.0-incubating,'\n",
    "               'org.datasyslab:geotools-wrapper:1.1.0-25.2'). \\\n",
    "        getOrCreate()\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty(\"sedona.global.charset\", \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = ShapefileReader.readToGeometryRDD(sc, \"data/drive-download-20220720T150603Z-001/census\")\n",
    "census_df = Adapter.toDf(census, spark)\n",
    "census_df.createOrReplaceTempView(\"census\")\n",
    "census_df.printSchema()\n",
    "\n",
    "subway = ShapefileReader.readToGeometryRDD(sc, \"data/drive-download-20220720T150603Z-001/subway\")\n",
    "subway_df = Adapter.toDf(subway, spark)\n",
    "subway_df.createOrReplaceTempView(\"subway\")\n",
    "subway_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.sql(\"SELECT Sum(popn_total) FROM census\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = spark.sql(\"WITH distinct_blocks AS ( SELECT DISTINCT (blkid) popn_total FROM census JOIN subway ON ST_DWithin(census.geom, subway.geom, 500)) SELECT Sum(popn_total) FROM distinct_blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = spark.sql(\"SELECT sum(popn_total) FROM census JOIN subway ON ST_DWithin(census.geometry, subway.geometry, 500)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
